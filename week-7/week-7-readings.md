# Week-7: Review - Preparations

According to our [syllabus](../syllabus/Fall20_syllabus.pdf) this week you would share your projects with the rest of the class. However, because of the size of the class this option is not feasible any more. So instead, we will enjoy having a little bit of extra time to polish some of the topics we already discussed. 

Here are some of the topics that come to my mind. 

## Regression

- Diagnosis of residual plots

You can read section 3.3.3, 'Potential Problems', of ISLR (p92 - p102). 

- Especially focus on the definitions of `outliers`, `leverage`, `collinearity`, `time series` and `heteroscedasticity`. 

- What are the suggested solutions for each of the possible problems?

## Classification

I want to talk more about classification evaluation metrics. 

- Especially, recall, precision and ROC curves. 

You can read `Performance Measures` section of chapter-3 of Hands-on Machine Learning with Scikit-learn, Keras, and TensorFlow. (Both first edition and second edition have this chapter so it doesn't really matter which one you have.)

- We can discuss more on multi-class classification problem.

- Finally we can discuss imbalance target variable problem in classification problems. 

## Bootstrap and Random Forests

Finally, if time allows we can talk on bootstrapping and its use in Random Forests. 

- You can read 5.2 from ISLR for bootstrapping and 8.2 for its application in Tree-Based Methods. 

## Extra

If you were able to finish the project, read the material above, and still want to read more about ML:

Chapter-6: Learning Best Practices for Model Evaluation and Hyperparameter Tuning from Python Machine Learning p191 -  p222 (I use the 3rd edition but in the 2nd edition this chapter should be more or less exactly the same.)